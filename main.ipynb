{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание датасета CrossNER\n",
    "\n",
    "**Источник:** [Статья (PDF)](https://arxiv.org/pdf/2012.04373)\n",
    "\n",
    "Датасет **CrossNER** разработан для оценки и изучения способности моделей распознавания именованных сущностей (NER) к обобщению между различными доменами. Он содержит данные из шести областей (доменных подсекций), извлечённые из английской Википедии, а также включает классический набор данных CoNLL2003:\n",
    "\n",
    "- **AI**: Данные о темах, связанных с искусственным интеллектом.\n",
    "- **Literature**: Тексты о литературных произведениях, писателях, жанрах.\n",
    "- **Music**: Материалы о музыке, исполнителях, композициях, жанрах.\n",
    "- **Politics**: Информация о политиках, политических событиях, партиях.\n",
    "- **Science**: Данные о научных концептах, учёных, открытиях.\n",
    "- **CoNLL2003**: Классический эталонный датасет для NER для сравнения.\n",
    "\n",
    "Каждая доменная подсекция содержит свои специфические типы именованных сущностей, что позволяет оценить способность моделей обобщать знания, полученные в одном домене, на другие.\n",
    "\n",
    "Структура и особенности датасета:\n",
    "- Доступны три сплита для каждой доменной подсекции: `train`, `validation`, `test`.\n",
    "- Набор сущностей и их распределение сильно варьируются от домена к домену.\n",
    "- Датасет был создан для исследования междоменного переноса и устойчивости NER-моделей. В частности: CoNLL2003 рассматривался как source dataset, a остальные 5 доменов, как target dataset.\n",
    "\n",
    "![image.png](images/1.png)\n",
    "\n",
    "**Здесь будет изображение с таблицей статистических характеристик датасета (количество предложений, токенов, сущностей для каждого домена)**\n",
    "\n",
    "Применение:\n",
    "- Оценка качества и устойчивости моделей NER при переходе между доменами.\n",
    "- Изучение влияния доменных различий на результаты распознавания сущностей.\n",
    "- Разработка более универсальных и обобщающих NER-моделей, способных работать в условиях значительных доменных сдвигов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО! Так как некоторая оценка и исследование проведено в статье оригинального датасета и их легко \"сравнить\", давайте попробуем сделать так, чтобы представленные методы метчились в оценками, приведенными в статье. У нас не стоит задача превзойти метрики, представленные там, поскольку нам важно не происследовать перенос с одного домена на другой, а обучить модель, способную на всем представленном датасете (общем) получить похожие метрики и необязательно презвойти их (иначе это не тянет на 2х недельную лабу).\n",
    "\n",
    "ВАЖНО 2: так как наши одногруппники взяли в рассмотрение одиночный датасет **CoNLL2003**, а он содержится в наших данных мы его не будем выкидывать, но основная наша цель - работать и получать метрики по другим (target) датасетам, однако мы на всякий случай решили оставить **CoNLL2003**, на случай, если содержание этого датасета в наших расширенных данных не вызовет проблем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "subsections = [\"ai\", \"conll2003\", \"literature\", \"music\", \"politics\", \"science\"]\n",
    "\n",
    "train_datasets = []\n",
    "val_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for subsection in subsections:\n",
    "    ds = load_dataset(\"DFKI-SLT/cross_ner\", subsection)\n",
    "    # Добавляем колонку \"source\"\n",
    "    ds_train = ds[\"train\"].map(lambda x: {\"source\": subsection})\n",
    "    ds_val = ds[\"validation\"].map(lambda x: {\"source\": subsection})\n",
    "    ds_test = ds[\"test\"].map(lambda x: {\"source\": subsection})\n",
    "    \n",
    "    # Собираем в списки\n",
    "    train_datasets.append(ds_train)\n",
    "    val_datasets.append(ds_val)\n",
    "    test_datasets.append(ds_test)\n",
    "\n",
    "# Объединяем все в единые датасеты\n",
    "train_dataset = concatenate_datasets(train_datasets)\n",
    "val_dataset = concatenate_datasets(val_datasets)\n",
    "test_dataset = concatenate_datasets(test_datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть три датасета: train_dataset, val_dataset, test_dataset.\n",
    "Каждый пример содержит колонку \"source\" с указанием исходной подсекции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'ner_tags', 'source'],\n",
       "    num_rows: 14741\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как выглядят данные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим первый элемент данных, мы видим, что для каждого элемента данных мы имеем:\n",
    "- индекс конкретного элемента, \n",
    "- токены, которые представляют собой каждое отдельно слово\n",
    "- уже закодированные теги каждого слов\n",
    "- источник или домен данных, чтобы понимать, из какого датасета данный конкретный пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Popular</td>\n",
       "      <td>0</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>approaches</td>\n",
       "      <td>0</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>opinion-based</td>\n",
       "      <td>59</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>recommender</td>\n",
       "      <td>60</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>)</td>\n",
       "      <td>0</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>:</td>\n",
       "      <td>0</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>e12957</td>\n",
       "      <td>0</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         tokens  ner_tags source\n",
       "0   0        Popular         0     ai\n",
       "1   0     approaches         0     ai\n",
       "2   0             of         0     ai\n",
       "3   0  opinion-based        59     ai\n",
       "4   0    recommender        60     ai\n",
       ".. ..            ...       ...    ...\n",
       "59  0              5         0     ai\n",
       "60  0              )         0     ai\n",
       "61  0              :         0     ai\n",
       "62  0         e12957         0     ai\n",
       "63  0              .         0     ai\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ для тегов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте поближе посмотрим на кодировку:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что это?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-academicjournal',\n",
       " 2: 'I-academicjournal',\n",
       " 3: 'B-album',\n",
       " 4: 'I-album',\n",
       " 5: 'B-algorithm',\n",
       " 6: 'I-algorithm',\n",
       " 7: 'B-astronomicalobject',\n",
       " 8: 'I-astronomicalobject',\n",
       " 9: 'B-award',\n",
       " 10: 'I-award',\n",
       " 11: 'B-band',\n",
       " 12: 'I-band',\n",
       " 13: 'B-book',\n",
       " 14: 'I-book',\n",
       " 15: 'B-chemicalcompound',\n",
       " 16: 'I-chemicalcompound',\n",
       " 17: 'B-chemicalelement',\n",
       " 18: 'I-chemicalelement',\n",
       " 19: 'B-conference',\n",
       " 20: 'I-conference',\n",
       " 21: 'B-country',\n",
       " 22: 'I-country',\n",
       " 23: 'B-discipline',\n",
       " 24: 'I-discipline',\n",
       " 25: 'B-election',\n",
       " 26: 'I-election',\n",
       " 27: 'B-enzyme',\n",
       " 28: 'I-enzyme',\n",
       " 29: 'B-event',\n",
       " 30: 'I-event',\n",
       " 31: 'B-field',\n",
       " 32: 'I-field',\n",
       " 33: 'B-literarygenre',\n",
       " 34: 'I-literarygenre',\n",
       " 35: 'B-location',\n",
       " 36: 'I-location',\n",
       " 37: 'B-magazine',\n",
       " 38: 'I-magazine',\n",
       " 39: 'B-metrics',\n",
       " 40: 'I-metrics',\n",
       " 41: 'B-misc',\n",
       " 42: 'I-misc',\n",
       " 43: 'B-musicalartist',\n",
       " 44: 'I-musicalartist',\n",
       " 45: 'B-musicalinstrument',\n",
       " 46: 'I-musicalinstrument',\n",
       " 47: 'B-musicgenre',\n",
       " 48: 'I-musicgenre',\n",
       " 49: 'B-organisation',\n",
       " 50: 'I-organisation',\n",
       " 51: 'B-person',\n",
       " 52: 'I-person',\n",
       " 53: 'B-poem',\n",
       " 54: 'I-poem',\n",
       " 55: 'B-politicalparty',\n",
       " 56: 'I-politicalparty',\n",
       " 57: 'B-politician',\n",
       " 58: 'I-politician',\n",
       " 59: 'B-product',\n",
       " 60: 'I-product',\n",
       " 61: 'B-programlang',\n",
       " 62: 'I-programlang',\n",
       " 63: 'B-protein',\n",
       " 64: 'I-protein',\n",
       " 65: 'B-researcher',\n",
       " 66: 'I-researcher',\n",
       " 67: 'B-scientist',\n",
       " 68: 'I-scientist',\n",
       " 69: 'B-song',\n",
       " 70: 'I-song',\n",
       " 71: 'B-task',\n",
       " 72: 'I-task',\n",
       " 73: 'B-theory',\n",
       " 74: 'I-theory',\n",
       " 75: 'B-university',\n",
       " 76: 'I-university',\n",
       " 77: 'B-writer',\n",
       " 78: 'I-writer'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2id = {\"O\": 0, \"B-academicjournal\": 1, \"I-academicjournal\": 2, \"B-album\": 3, \"I-album\": 4, \"B-algorithm\": 5, \"I-algorithm\": 6, \"B-astronomicalobject\": 7, \"I-astronomicalobject\": 8, \"B-award\": 9, \"I-award\": 10, \"B-band\": 11, \"I-band\": 12, \"B-book\": 13, \"I-book\": 14, \"B-chemicalcompound\": 15, \"I-chemicalcompound\": 16, \"B-chemicalelement\": 17, \"I-chemicalelement\": 18, \"B-conference\": 19, \"I-conference\": 20, \"B-country\": 21, \"I-country\": 22, \"B-discipline\": 23, \"I-discipline\": 24, \"B-election\": 25, \"I-election\": 26, \"B-enzyme\": 27, \"I-enzyme\": 28, \"B-event\": 29, \"I-event\": 30, \"B-field\": 31, \"I-field\": 32, \"B-literarygenre\": 33, \"I-literarygenre\": 34, \"B-location\": 35, \"I-location\": 36, \"B-magazine\": 37, \"I-magazine\": 38, \"B-metrics\": 39, \"I-metrics\": 40, \"B-misc\": 41, \"I-misc\": 42, \"B-musicalartist\": 43, \"I-musicalartist\": 44, \"B-musicalinstrument\": 45, \"I-musicalinstrument\": 46, \"B-musicgenre\": 47, \"I-musicgenre\": 48, \"B-organisation\": 49, \"I-organisation\": 50, \"B-person\": 51, \"I-person\": 52, \"B-poem\": 53, \"I-poem\": 54, \"B-politicalparty\": 55, \"I-politicalparty\": 56, \"B-politician\": 57, \"I-politician\": 58, \"B-product\": 59, \"I-product\": 60, \"B-programlang\": 61, \"I-programlang\": 62, \"B-protein\": 63, \"I-protein\": 64, \"B-researcher\": 65, \"I-researcher\": 66, \"B-scientist\": 67, \"I-scientist\": 68, \"B-song\": 69, \"I-song\": 70, \"B-task\": 71, \"I-task\": 72, \"B-theory\": 73, \"I-theory\": 74, \"B-university\": 75, \"I-university\": 76, \"B-writer\": 77, \"I-writer\": 78}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}\n",
    "id2tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что для каждой сущности, например сущность писатель (writer) есть две метки: начало метки ('B-writer') и то, что еще находится в этой метке ('I-writer'). Метка 'O' предсталяет из себя лейбл для всех неименнованных сущностей, то есть тех сущностей, которые нас не интересуют. Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ners</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Popular</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>approaches</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opinion-based</td>\n",
       "      <td>B-product</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recommender</td>\n",
       "      <td>I-product</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>system</td>\n",
       "      <td>I-product</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>utilize</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>various</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>techniques</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>including</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tokens       ners  ner_tags\n",
       "0        Popular          O         0\n",
       "1     approaches          O         0\n",
       "2             of          O         0\n",
       "3  opinion-based  B-product        59\n",
       "4    recommender  I-product        60\n",
       "5         system  I-product        60\n",
       "6        utilize          O         0\n",
       "7        various          O         0\n",
       "8     techniques          O         0\n",
       "9      including          O         0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = pd.DataFrame(train_dataset[0])\n",
    "example[\"ners\"] = example[\"ner_tags\"].apply(lambda x: id2tag[x])\n",
    "example[[\"tokens\", \"ners\", \"ner_tags\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом мы понимаем, что `opinion-based recommender system` - это какой-то продукт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пересекаются ли лейблы теги между датасетами?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение тегов по общему датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение тегов по каждой сабсекции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пересечение вокабуляра между датасетами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".anya_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
